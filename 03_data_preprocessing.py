"""
PREPROCESAMIENTO DE DATOS - SF TRANSIT
Feature Engineering + Limpieza + TransformaciÃ³n para ML
Autor: Francisco Narvaez M
Fecha: 2025-11-12
"""

import psycopg2
import pandas as pd
import numpy as np
from datetime import datetime
from math import radians, cos, sin, asin, sqrt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURACIÃ“N
# ============================================================================

DB_CONFIG = {
    'host': 'karenserver.postgres.database.azure.com',
    'database': 'transit_streaming',
    'user': 'admin_karen',
    'password': 'Tiendala60',
    'port': 5432
}

# Centro geogrÃ¡fico de San Francisco (calculado del anÃ¡lisis exploratorio)
SF_CENTER_LAT = 37.759011
SF_CENTER_LON = -122.358909

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

def haversine(lat1, lon1, lat2, lon2):
    """Calcular distancia entre dos puntos GPS en km"""
    R = 6371
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    return R * c

def connect_db():
    """Conectar a la base de datos"""
    return psycopg2.connect(**DB_CONFIG)

def get_vehicle_positions(conn, hours=48):
    """Obtener posiciones de vehÃ­culos"""
    query = f"""
        SELECT 
            id,
            vehicle_id,
            route_id,
            trip_id,
            agency_id,
            latitude,
            longitude,
            speed,
            heading,
            timestamp,
            created_at
        FROM vehicle_positions
        WHERE timestamp > NOW() - INTERVAL '{hours} hours'
        ORDER BY vehicle_id, timestamp ASC
    """
    return pd.read_sql(query, conn)

# ============================================================================
# FEATURE ENGINEERING
# ============================================================================

def calculate_speed_from_positions(df):
    """Calcular velocidad desde posiciones GPS"""
    print("\nðŸ”„ Calculando velocidades desde GPS...")
    
    df = df.copy().sort_values(['vehicle_id', 'timestamp']).reset_index(drop=True)
    df['speed_calculated'] = np.nan
    df['distance_traveled'] = np.nan
    df['time_diff_seconds'] = np.nan
    
    for vehicle_id in df['vehicle_id'].unique():
        mask = df['vehicle_id'] == vehicle_id
        indices = df[mask].index.tolist()
        
        for i in range(1, len(indices)):
            prev_idx = indices[i-1]
            curr_idx = indices[i]
            
            prev_row = df.loc[prev_idx]
            curr_row = df.loc[curr_idx]
            
            distance = haversine(
                prev_row['latitude'], prev_row['longitude'],
                curr_row['latitude'], curr_row['longitude']
            )
            
            time_diff = (curr_row['timestamp'] - prev_row['timestamp']).total_seconds()
            
            if time_diff > 0:
                speed = (distance / time_diff) * 3600
                if speed <= 150:
                    df.loc[curr_idx, 'speed_calculated'] = speed
                    df.loc[curr_idx, 'distance_traveled'] = distance
                    df.loc[curr_idx, 'time_diff_seconds'] = time_diff
    
    print(f"âœ… Velocidades calculadas: {df['speed_calculated'].notna().sum():,} registros")
    return df

def calculate_acceleration(df):
    """Calcular aceleraciÃ³n (cambio de velocidad)"""
    print("\nðŸ”„ Calculando aceleraciones...")
    
    df = df.copy().sort_values(['vehicle_id', 'timestamp']).reset_index(drop=True)
    df['acceleration'] = np.nan
    
    for vehicle_id in df['vehicle_id'].unique():
        mask = df['vehicle_id'] == vehicle_id
        vehicle_data = df[mask].copy()
        
        # Calcular cambio de velocidad / tiempo
        speed_diff = vehicle_data['speed_calculated'].diff()
        time_diff = vehicle_data['time_diff_seconds']
        
        # AceleraciÃ³n en m/sÂ²
        acceleration = (speed_diff / 3.6) / time_diff  # convertir km/h a m/s
        
        df.loc[mask, 'acceleration'] = acceleration
    
    print(f"âœ… Aceleraciones calculadas: {df['acceleration'].notna().sum():,} registros")
    return df

def create_temporal_features(df):
    """Crear features temporales"""
    print("\nðŸ”„ Creando features temporales...")
    
    df['hour'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    df['day_name'] = df['timestamp'].dt.day_name()
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
    
    # Hora pico: 7-9am y 5-7pm
    df['is_rush_hour'] = (
        ((df['hour'] >= 7) & (df['hour'] <= 9)) |
        ((df['hour'] >= 17) & (df['hour'] <= 19))
    ).astype(int)
    
    # Periodo del dÃ­a
    def time_of_day(hour):
        if 5 <= hour < 12:
            return 'morning'
        elif 12 <= hour < 17:
            return 'afternoon'
        elif 17 <= hour < 21:
            return 'evening'
        else:
            return 'night'
    
    df['time_of_day'] = df['hour'].apply(time_of_day)
    
    print("âœ… Features temporales creados")
    return df

def create_geographic_features(df):
    """Crear features geogrÃ¡ficos"""
    print("\nðŸ”„ Creando features geogrÃ¡ficos...")
    
    # Distancia al centro de SF
    df['distance_to_center'] = df.apply(
        lambda row: haversine(SF_CENTER_LAT, SF_CENTER_LON, 
                             row['latitude'], row['longitude']),
        axis=1
    )
    
    # Zona geogrÃ¡fica (basado en latitud/longitud)
    def get_zone(lat, lon):
        if lat > SF_CENTER_LAT + 0.05:
            return 'north'
        elif lat < SF_CENTER_LAT - 0.05:
            return 'south'
        elif lon > SF_CENTER_LON + 0.05:
            return 'east'
        elif lon < SF_CENTER_LON - 0.05:
            return 'west'
        else:
            return 'central'
    
    df['zone'] = df.apply(lambda row: get_zone(row['latitude'], row['longitude']), axis=1)
    
    # Â¿EstÃ¡ en downtown? (dentro de 5km del centro)
    df['is_in_downtown'] = (df['distance_to_center'] < 5).astype(int)
    
    print("âœ… Features geogrÃ¡ficos creados")
    return df

def create_movement_features(df):
    """Crear features de movimiento"""
    print("\nðŸ”„ Creando features de movimiento...")
    
    # CategorÃ­as de velocidad
    df['is_stopped'] = (df['speed_calculated'] < 5).astype(int)
    df['is_moving_slow'] = ((df['speed_calculated'] >= 5) & 
                            (df['speed_calculated'] < 30)).astype(int)
    df['is_moving_normal'] = ((df['speed_calculated'] >= 30) & 
                              (df['speed_calculated'] < 60)).astype(int)
    df['is_moving_fast'] = (df['speed_calculated'] >= 60).astype(int)
    
    # CategorÃ­a de velocidad
    def speed_category(speed):
        if pd.isna(speed):
            return 'unknown'
        elif speed < 5:
            return 'stopped'
        elif speed < 30:
            return 'slow'
        elif speed < 60:
            return 'normal'
        else:
            return 'fast'
    
    df['speed_category'] = df['speed_calculated'].apply(speed_category)
    
    # Cambio de direcciÃ³n (heading)
    df = df.sort_values(['vehicle_id', 'timestamp']).reset_index(drop=True)
    df['heading_change'] = df.groupby('vehicle_id')['heading'].diff().abs()
    
    print("âœ… Features de movimiento creados")
    return df

def create_vehicle_aggregates(df):
    """Crear features agregados por vehÃ­culo"""
    print("\nðŸ”„ Creando agregados por vehÃ­culo...")
    
    # Agregados por vehÃ­culo
    vehicle_stats = df.groupby('vehicle_id').agg({
        'speed_calculated': ['mean', 'std', 'max'],
        'distance_traveled': 'sum',
        'is_stopped': 'sum',
        'timestamp': 'count'
    }).reset_index()
    
    vehicle_stats.columns = [
        'vehicle_id', 
        'avg_speed_vehicle', 
        'std_speed_vehicle', 
        'max_speed_vehicle',
        'total_distance_vehicle',
        'num_stops_vehicle',
        'num_readings_vehicle'
    ]
    
    # Merge con el dataframe original
    df = df.merge(vehicle_stats, on='vehicle_id', how='left')
    
    print("âœ… Agregados por vehÃ­culo creados")
    return df

# ============================================================================
# LIMPIEZA DE DATOS
# ============================================================================

def remove_duplicates(df):
    """Eliminar duplicados"""
    print("\nðŸ§¹ Eliminando duplicados...")
    initial_count = len(df)
    df = df.drop_duplicates(subset=['vehicle_id', 'timestamp'], keep='first')
    removed = initial_count - len(df)
    print(f"âœ… Duplicados eliminados: {removed:,}")
    return df

def handle_missing_values(df):
    """Manejar valores nulos"""
    print("\nðŸ§¹ Manejando valores nulos...")
    
    # Mostrar nulos antes
    print("\nNulos antes:")
    print(df.isnull().sum()[df.isnull().sum() > 0])
    
    # Estrategias:
    # - route_id, trip_id: llenar con 'unknown'
    # - speed_calculated: ya manejados (NaN para primer registro de cada vehÃ­culo)
    # - heading: llenar con forward fill por vehÃ­culo
    
    df['route_id'] = df['route_id'].fillna('unknown')
    df['trip_id'] = df['trip_id'].fillna('unknown')
    df['heading'] = df.groupby('vehicle_id')['heading'].fillna(method='ffill')
    
    # Para features calculados, llenar con 0 o valores por defecto
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].isnull().sum() > 0:
            df[col] = df[col].fillna(0)
    
    print("\nNulos despuÃ©s:")
    print(df.isnull().sum()[df.isnull().sum() > 0])
    
    print("âœ… Valores nulos manejados")
    return df

def filter_outliers(df):
    """Filtrar outliers extremos"""
    print("\nðŸ§¹ Filtrando outliers...")
    
    initial_count = len(df)
    
    # Filtrar coordenadas fuera del Ã¡rea de SF Bay
    df = df[
        (df['latitude'] >= 37.0) & (df['latitude'] <= 38.0) &
        (df['longitude'] >= -123.0) & (df['longitude'] <= -121.5)
    ]
    
    # Filtrar velocidades imposibles (ya filtradas a 150 km/h)
    # Filtrar aceleraciones extremas (> 10 m/sÂ²)
    df = df[df['acceleration'].abs() <= 10]
    
    removed = initial_count - len(df)
    print(f"âœ… Outliers eliminados: {removed:,}")
    
    return df

# ============================================================================
# TRANSFORMACIONES PARA ML
# ============================================================================

def encode_categorical(df):
    """Encodear variables categÃ³ricas"""
    print("\nðŸ”„ Encodeando variables categÃ³ricas...")
    
    # Label Encoding para variables con orden
    le_agency = LabelEncoder()
    df['agency_encoded'] = le_agency.fit_transform(df['agency_id'])
    
    # One-hot encoding para variables sin orden (se harÃ¡ en el modelo)
    # Por ahora solo preparamos las columnas
    
    print("âœ… Variables categÃ³ricas encodeadas")
    print(f"   Agencias: {dict(zip(le_agency.classes_, le_agency.transform(le_agency.classes_)))}")
    
    return df, le_agency

def normalize_features(df):
    """Normalizar features numÃ©ricos"""
    print("\nðŸ”„ Normalizando features...")
    
    # Seleccionar features numÃ©ricos para normalizar
    features_to_normalize = [
        'latitude', 'longitude', 'heading',
        'speed_calculated', 'distance_traveled', 'acceleration',
        'distance_to_center', 'heading_change',
        'avg_speed_vehicle', 'std_speed_vehicle', 'max_speed_vehicle',
        'total_distance_vehicle'
    ]
    
    # Crear copia de features originales
    for feat in features_to_normalize:
        if feat in df.columns:
            df[f'{feat}_original'] = df[feat]
    
    # Normalizar
    scaler = StandardScaler()
    df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])
    
    print("âœ… Features normalizados")
    return df, scaler

def prepare_for_ml(df):
    """Preparar dataset final para ML"""
    print("\nðŸ”„ Preparando dataset para ML...")
    
    # Seleccionar features relevantes
    feature_columns = [
        # Temporales
        'hour', 'day_of_week', 'is_weekend', 'is_rush_hour',
        # GeogrÃ¡ficos
        'latitude', 'longitude', 'distance_to_center', 'zone',
        # Movimiento
        'speed_calculated', 'acceleration', 'heading', 'heading_change',
        'is_stopped', 'is_moving_slow', 'is_moving_normal', 'is_moving_fast',
        # Agregados
        'avg_speed_vehicle', 'std_speed_vehicle', 'max_speed_vehicle',
        'total_distance_vehicle', 'num_stops_vehicle',
        # CategÃ³ricos
        'agency_encoded', 'route_id'
    ]
    
    # Filtrar solo columnas que existen
    feature_columns = [col for col in feature_columns if col in df.columns]
    
    df_ml = df[feature_columns + ['vehicle_id', 'timestamp']].copy()
    
    print(f"âœ… Dataset preparado con {len(feature_columns)} features")
    return df_ml

def split_train_test(df, test_size=0.2):
    """Dividir en train y test"""
    print(f"\nðŸ”„ Dividiendo en train ({int((1-test_size)*100)}%) y test ({int(test_size*100)}%)...")
    
    # Dividir por tiempo (mÃ¡s realista para series temporales)
    df = df.sort_values('timestamp')
    split_idx = int(len(df) * (1 - test_size))
    
    train_df = df.iloc[:split_idx]
    test_df = df.iloc[split_idx:]
    
    print(f"âœ… Train: {len(train_df):,} registros")
    print(f"âœ… Test: {len(test_df):,} registros")
    
    return train_df, test_df

# ============================================================================
# GUARDAR DATASETS
# ============================================================================

def save_datasets(df_original, df_engineered, train_df, test_df):
    """Guardar datasets procesados"""
    print("\nðŸ’¾ Guardando datasets...")
    
    import os
    os.makedirs('data/processed', exist_ok=True)
    
    # Guardar datos originales con features
    df_original.to_csv('data/processed/data_original.csv', index=False)
    print(f"   âœ… data_original.csv ({len(df_original):,} registros)")
    
    # Guardar datos con feature engineering
    df_engineered.to_csv('data/processed/data_engineered.csv', index=False)
    print(f"   âœ… data_engineered.csv ({len(df_engineered):,} registros)")
    
    # Guardar train y test
    train_df.to_csv('data/processed/train_data.csv', index=False)
    print(f"   âœ… train_data.csv ({len(train_df):,} registros)")
    
    test_df.to_csv('data/processed/test_data.csv', index=False)
    print(f"   âœ… test_data.csv ({len(test_df):,} registros)")
    
    print("\nâœ… Todos los datasets guardados en data/processed/")

def generate_report(df_original, df_final):
    """Generar reporte de preprocesamiento"""
    print("\n" + "="*70)
    print("ðŸ“Š REPORTE DE PREPROCESAMIENTO")
    print("="*70)
    
    print(f"\nðŸ“ Registros:")
    print(f"   â€¢ Originales: {len(df_original):,}")
    print(f"   â€¢ Finales: {len(df_final):,}")
    print(f"   â€¢ Removidos: {len(df_original) - len(df_final):,} ({(len(df_original)-len(df_final))/len(df_original)*100:.1f}%)")
    
    print(f"\nðŸ“Š Features:")
    print(f"   â€¢ Originales: {len(df_original.columns)}")
    print(f"   â€¢ Finales: {len(df_final.columns)}")
    print(f"   â€¢ Nuevos: {len(df_final.columns) - len(df_original.columns)}")
    
    print(f"\nðŸ“ˆ EstadÃ­sticas de velocidad:")
    print(f"   â€¢ Media: {df_final['speed_calculated'].mean():.2f} km/h")
    print(f"   â€¢ Mediana: {df_final['speed_calculated'].median():.2f} km/h")
    print(f"   â€¢ DesviaciÃ³n: {df_final['speed_calculated'].std():.2f} km/h")
    
    print(f"\nðŸš¦ DistribuciÃ³n de movimiento:")
    print(f"   â€¢ Detenidos: {df_final['is_stopped'].sum():,} ({df_final['is_stopped'].sum()/len(df_final)*100:.1f}%)")
    print(f"   â€¢ Lento: {df_final['is_moving_slow'].sum():,} ({df_final['is_moving_slow'].sum()/len(df_final)*100:.1f}%)")
    print(f"   â€¢ Normal: {df_final['is_moving_normal'].sum():,} ({df_final['is_moving_normal'].sum()/len(df_final)*100:.1f}%)")
    print(f"   â€¢ RÃ¡pido: {df_final['is_moving_fast'].sum():,} ({df_final['is_moving_fast'].sum()/len(df_final)*100:.1f}%)")

# ============================================================================
# MAIN
# ============================================================================

def main():
    print("\n" + "="*70)
    print("ðŸ”§ PREPROCESAMIENTO DE DATOS - SF TRANSIT")
    print("="*70)
    
    # 1. Conectar y extraer datos
    print("\nðŸ”Œ Conectando a la base de datos...")
    conn = connect_db()
    print("âœ… ConexiÃ³n establecida")
    
    print("\nðŸ“¥ Extrayendo datos...")
    df = get_vehicle_positions(conn, hours=48)
    conn.close()
    print(f"âœ… Datos extraÃ­dos: {len(df):,} registros")
    
    df_original = df.copy()
    
    # 2. Feature Engineering
    print("\n" + "="*70)
    print("ðŸ› ï¸  FEATURE ENGINEERING")
    print("="*70)
    
    df = calculate_speed_from_positions(df)
    df = calculate_acceleration(df)
    df = create_temporal_features(df)
    df = create_geographic_features(df)
    df = create_movement_features(df)
    df = create_vehicle_aggregates(df)
    
    # 3. Limpieza
    print("\n" + "="*70)
    print("ðŸ§¹ LIMPIEZA DE DATOS")
    print("="*70)
    
    df = remove_duplicates(df)
    df = handle_missing_values(df)
    df = filter_outliers(df)
    
    df_engineered = df.copy()
    
    # 4. Transformaciones para ML
    print("\n" + "="*70)
    print("ðŸ¤– TRANSFORMACIONES PARA ML")
    print("="*70)
    
    df, le_agency = encode_categorical(df)
    # df, scaler = normalize_features(df)  # Comentado: normalizar en el modelo
    df_ml = prepare_for_ml(df)
    train_df, test_df = split_train_test(df_ml, test_size=0.2)
    
    # 5. Guardar datasets
    save_datasets(df_original, df_engineered, train_df, test_df)
    
    # 6. Generar reporte
    generate_report(df_original, df_engineered)
    
    print("\n" + "="*70)
    print("âœ… PREPROCESAMIENTO COMPLETADO")
    print("="*70)
    print("\nðŸ“ Archivos generados:")
    print("   â€¢ data/processed/data_original.csv")
    print("   â€¢ data/processed/data_engineered.csv")
    print("   â€¢ data/processed/train_data.csv")
    print("   â€¢ data/processed/test_data.csv")
    print("\nðŸš€ Listo para entrenar modelos de Machine Learning!")

if __name__ == "__main__":
    main()
